%% This is file `example.tex',

%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% coppe.dtx  (with options: `example')
%% 
%% This is a sample monograph which illustrates the use of `coppe' document
%% class and `coppe-unsrt' BibTeX style.
%% 
%% \CheckSum{1620}
%% \CharacterTable
%%  {Upper-case    \A\B\C\D\E\F\G\H\I\J\K\L\M\N\O\P\Q\R\S\T\U\V\W\X\Y\Z
%%   Lower-case    \a\b\c\d\e\f\g\h\i\j\k\l\m\n\o\p\q\r\s\t\u\v\w\x\y\z
%%   Digits        \0\1\2\3\4\5\6\7\8\9
%%   Exclamation   \!     Double quote  \"     Hash (number) \#
%%   Dollar        \$     Percent       \%     Ampersand     \&
%%   Acute accent  \'     Left paren    \(     Right paren   \)
%%   Asterisk      \*     Plus          \+     Comma         \,
%%   Minus         \-     Point         \.     Solidus       \/
%%   Colon         \:     Semicolon     \;     Less than     \<
%%   Equals        \=     Greater than  \>     Question mark \?
%%   Commercial at \@     Left bracket  \[     Backslash     \\
%%   Right bracket \]     Circumflex    \^     Underscore    \_
%%   Grave accent  \`     Left brace    \{     Vertical bar  \|
%%   Right brace   \}     Tilde         \~}
%%
\documentclass[dsc,english]{coppe}
\usepackage{natbib}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{booktabs} 
\usepackage{subcaption}
\usepackage{amsthm}
\usepackage{url}
\usepackage{lineno}
\usepackage{enumerate}

\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{hypothesis}{Hypothesis}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\FTL}{FTL}



\linenumbers % Enable line numbering
\modulolinenumbers[5] % Set line numbering interval


\makelosymbols
\makeloabbreviations

\begin{document}
  \title{Função de custo e penalização robustas para aprendizado de máquina justo}
  \foreigntitle{Robust loss and penalty to fair machine learning}
  \author{Ygor}{de Mello Canalli}
  \advisor{Prof.}{Geraldo}{Zimbrão da Silva}{D.Sc.}
  \advisor{Prof.}{Filipe}{Braida do Carmo}{D.Sc.}

  \examiner{Prof.}{Geraldo Zimbrão da Silva}{D.Sc.}
  \examiner{Prof.}{Filipe Braida do Carmo}{D.Sc.}
  \examiner{Prof.}{Geraldo Bonorino Xexéo}{D.Sc.}
  \examiner{Prof.}{Daniel Sadoc Menasché}{Ph.D}
  \examiner{Prof.}{Carlos Eduardo Ribeiro de Mello}{Ph.D.}
  \department{PESC}
  \date{08}{2024}

  \keyword{Fair machine learning}
  \keyword{Label noise robustness}
  \keyword{Multi-objective optimization}
  \keyword{Redlining effect}

  \maketitle

  \frontmatter
  \dedication{A algu\'em cujo valor \'e digno desta dedicat\'oria.}

  \chapter*{Agradecimentos}

  Gostaria de agradecer a todos.

  \begin{abstract}

A ampla adoção de aprendizado de máquina em decisões de impacto social expandiu sistematicamente a aplicação de padrões discriminatórios já existentes. Assim, técnicas de aprendizado de máquina justas tornaram-se uma fronteira para pesquisadores e profissionais de IA. Abordar a equidade é complexo, não se pode depender apenas dos dados usados para treinar modelos ou das métricas que os avaliam, pois esses dados frequentemente são a principal fonte de viés, similar a dados ruidosos. Exploramos a convergência entre equidade e ruído no aprendizado de máquina, destacando semelhanças e diferenças. Apresentamos “Fair Transition Loss”, um novo método para classificação justa inspirado em técnicas de robustez contra ruído de rótulo. Funções de custo convencionais ignoram a distribuição dos dados sensíveis e seu impacto nas previsões. Nossa abordagem utiliza matrizes de transição para ajustar as previsões utilizando estes dados ignorados. Nossa avaliação empírica usando o teste de significância de ordem quase-estocástica indica que esse método supera muitas abordagens clássicas e de ponta na maioria dos conjuntos de dados de referência e objetivos de otimização. Além disso, a abordagem proposta se mostrou a única a manter resultados competitivos em todos os cenários.

Além disso, apresentamos uma abordagem de regularização inovadora denominada “Redlining Penalty Regularization”, que penaliza proporcionalmente a dependência do modelo de preditores indiretos dos atributos sensíveis de acordo com suas correlações. Nossos resultados experimentais demonstram que a técnica proposta melhora os resultados tanto em redes neurais convencionais quanto naquelas treinadas usando o “Fair Transition Loss” em uma variedade de conjuntos de dados e objetivos de otimização para classificação justa.

  \end{abstract}

  \begin{foreignabstract}

The Machine learning widespread adoption has inadvertently led to the amplification of societal biases and discrimination, with many consequential decisions now influenced by data-driven systems. In this scenario, fair machine learning techniques has become a frontier for AI researchers and practitioners. Addressing fairness is intricate; one cannot solely rely on the data used to train models or the metrics that assess them, as this data is often the primary source of bias — akin to noisy data. This work delves into the convergence of these two research domains, highlighting the similarities and differences between fairness and noise in machine learning. We introduce the Fair Transition Loss, a novel method for fair classification inspired by label noise robustness techniques. Traditional loss functions tend to ignore distributions of sensitive features and their impact on outcomes. Our approach uses transition matrices to adjust predicted label probabilities based on this ignored data. The empirical evaluation using Almost Stochastic Order significance test indicates that this method outperforms many classical and state-of-art approaches in most of benchmarked datasets and optimization objectives to fair classification. Additionally, the proposed approach remains as the only to keep competitive results on all compared scenarios.

Also, we present the Redlining Penalty Regularization, a novel regularization approach that proportionately penalizes model’s dependency on sensitive feature proxies according their correlations. Our experimental results demonstrates that this proposed technique improves both results on standard neural networks and those trained using Fair Transition Loss on a variety of datasets and optimization objectives to fair classification.

  \end{foreignabstract}

  \tableofcontents
  \listoffigures
  \listoftables
  \printlosymbols
  \printloabbreviations

  \mainmatter
  
  \include{01_introduction}
  \include{02_fair_machine_learning_review}
  \include{03_fair_transition_loss}
  \include{04_redlining_penalty_regularization}
  \include{05_conclusions}

 
  %\chapter{Proposta}
  %\section{Ruído e Injustiça}
  %\section{Função de custo de transição para aprendizado justo}
  %\section{Correlação e preditores indiretos}
  %\section{Regularização}
  %\section{Ajuste de hiperparâmetros e matrizes de transição}

  %\chapter{Resultados e discussão}
  %\section{Significância para redes profundas}
  %\section{Estudo comparativo da função de custo de transição}
  %\section{Estudo comparativo com regularização}

  %\chapter{Conclusões}
  


  %\chapter{Conclusões}

  \backmatter
  \bibliographystyle{coppe-unsrt}
  \bibliography{thesis}

  %\appendix
  \include{appendix}
\end{document}
%% 
%%
%% End of file `example.tex'.
