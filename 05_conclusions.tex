\chapter{Conclusions}\label{chap:conclusions}


%\section{Considerations on the proposal}

In this work we introduced Fair Transition Loss, a novel approach to fair classification that estimates the influence of historical and societal biases on outcome probabilities for distinct social groups delineated by a sensitive feature. Drawing inspiration from label noise robustness, we represented these disparities on model's positive and negative outcomes probabilities to each social group using transition matrices, therefore incorporating this information onto the loss function to promote fairness. The proposed method hyperarameters were chosen by a Multi-Objective Optimization approach combining both fairness and model performance with a linear scalarization, defined in such a way that it is suitable to optimize a wide range of fairness and performance metrics.

Also, the present study proposed a novel regularization approach to fair classification named Redlining Penalty Regularization, which uses feature's correlation coefficient to the sensitive attribute to proportionately penalize model's dependency on it. Our empirical evaluation demonstrated that this approach effectively mitigate unfairness while keeping predictive performance, with benefits corresponding to redlining level on dataset. The proposed approach can be used on both standard neural networks and those trained with Fair Transition Loss to reduce bias while keeping predictive performance.

\section{Results and contributions}

Our experimental evaluation indicates that Fair Transition Loss consistently outperforms its competitors in most optimization scenarios. Even in those cases that the proposed method isn't the outright leader, it performs at least as well as evaluated alternatives, standing as the only model to keep competitive results in all scenarios. Therefore, this novel approach can significantly mitigate bias while keeping model performance, specially when optimizing balanced performance metrics like MCC. The proposed technique particularly stands out in setups where hyperparameter tuning procedures constitutes the prediction pipeline.

Furthermore, our results indicates that the Redlining Penalty Regularization approach effectively mitigates redlining effect on multiple datasets within various objective metrics when applied to both standard MLP and MLP trained with Fair Transition Loss. Also, our analysis indicates that the effectiveness of the referred approach is proportional to redlining level present on data, the higher the redlining the higher the performance-fairness trade-off improvement.

Thus, we summarize some contributions of the present study:

\begin{enumerate}[(i)]
    \item a novel loss correction approach inspired by label noise techniques to fair classification problems;
    \item a discussion of recent studies that lies between fairness and noise on machine learning;
    \item a multi-objective hyperparameter tuning approach do tackle the performance-fairness trade-off using a simple linear scalarization setup;
    \item a solid comparison of classic and state-of-art fair classification approaches using the Almost Stochastic Order as significance test;
    \item state-of-art results on various benchmarked datasets to fair classification using the proposed loss correction approach;
    \item a novel regularization approach that proportionately penalizes model's dependency on sensitive feature proxies according their correlations;
    \item improved results using the proposed regularization approach on standard MLPs to fair classification.
    \item improved state-of-art results using both the loss correction and regularization approaches to fair classification.
\end{enumerate}

\section{Research directions}

Here we outline some research direction insights, derived from proposed method's drawbacks and issues uncharted by this study:

\begin{enumerate}[(i)]
    \item explore approaches to estimating or initializing transition matrices to reduce computational costs required by hyperparameter optimization techniques;
    \item evaluate Fair Transition Loss within different neural network architectures, such as Deep Neural Networks;
    \item evaluate Fair Transition Loss on different data domains, such as image, audio and natural language;
    \item evaluate Fair Transition Loss optimization under non-linear scalarization setups, such as the Chebyshev scalarization scheme proposed by~\cite{Wei2022};
    \item evaluate Fair Transition Loss within different multi-objective optimization schemes, such as the Fair Hyperparameter Tuning techniques proposed by~\cite{Cruz2021};
    \item investigate whether Fair Transition Loss can effectively address multi-class fair classification problems and handle multiple sensitive attributes, as theoretically possible;
    \item evaluate Redlining Penalty Regularization within different neural network architectures, such as Deep Neural Networks;
    \item evaluate Redlining Penalty Regularization on different data domains, such as image, audio and natural language;
    \item evaluate Redlining Penalty Regularization combined with multiple pre-processing, in-processing and post-processing fair classification approaches.
    
\end{enumerate}

