\chapter{Chatterjee Redlining Penalty}

\section{Preliminaries}

The proposed regularization approach uses Chatterjee's xi correlation coefficient~\cite{}, which asses whether a random variable can be described as a function of another one, as a measure of the potential of given feature to be used by the model as a proxy to the sensitive feature. This phenomena, known as redlining effect, can lead model to produce indirect discrimination in their outcomes. Thus, the insight here is to penalize the use of those proxy features proportionally according Chatterjee's correlation in order to avoid redlining effed. Before discussing this approach, we start defining some common correlation coefficients and providing a proper comparison within Chatterjee's correlation. Also, we present some related approaches, specially those ones that, like ours, use regularization and penalty factors to avoid indirect discrimination.

The Pearson correlation coefficient, denoted by $\rho_{X,Y}$ and defined in Definition~\ref{def:pearson}, is a measure of the linear relationship between two random variables. The Pearson correlation coefficient ranges from $-1$ to $1$, where $1$ indicates a perfect positive linear relationship, $-1$ indicates a perfect negative linear relationship, and $0$ indicates no linear relationship.

\begin{definition}[Pearson correlation coefficient]\label{def:pearson}
Let  $X$ and $Y$\ random variables. The Pearson correlation coefficient between $X$ and $Y$ can be defined as  
\begin{equation}
\rho_{X,Y} = \frac{\mathrm{Cov}(X, Y)}{\sigma_X \sigma_Y},
\end{equation}
where $\mathrm{Cov}(X, Y)$ is the covariance between $X$ and $Y$, while $\sigma_X$ and $\sigma_Y$ the standard deviations of $X$ and $Y$, respectively. 
\end{definition}

Another relevant correlation coefficient is the Spearman's rank correlation coefficient. Firstly, we define the rank of a matrix, which measures the dimension of the vector space spanned by its rows or columns. More formally, the rank of a matrix can be defined according Definition~\ref{def:matrix_rank}.

\begin{definition}[Matrix Rank] \label{def:matrix_rank}
Let $\mathbf{A} \in \mathbb{R}^{m \times n}$ be a matrix with $m$ rows and $n$ columns. The rank of $\mathbf{A}$, denoted as $\text{rank}(\mathbf{A})$, is the maximum number of linearly independent rows (or columns) in the matrix.
\end{definition}

Spearman's rank correlation coefficient, denoted by $\rho_s$ and defined in Definition~\ref{def:spearman}, measures the strength and direction of the monotonic relationship between two ranked variables.  As like Pearson correlation coefficient, Spearman's rank correlation coefficient ranges from $-1$ to $1$, where $1$ indicates a perfect positive linear relationship, $-1$ indicates a perfect negative linear relationship, and $0$ indicates no linear relationship.
 
\begin{definition}[Spearman's correlation coefficient]\label{def:spearman}
Let  $X$ and $Y$\ random variables. Spearman's rank correlation coefficient  $\rho_s$ between $X$ and $Y$ can be defined as the Pearson correlation coefficient between the ranked variables, that is, 

\begin{equation}\label{eq:spearman}
\rho_s = \rho_{\rank(X),\rank(Y)} = \frac{\mathrm{Cov}(\rank(X), \rank(Y))}{\sigma_{\rank(X)} \sigma_{\rank(Y)}},
\end{equation}

where $\rank(X)$ and $\rank(Y)$ are the ranks of $X$ and $Y$, $\mathrm{Cov}(\rank(X), \rank(Y))$ is the covariance of the rank variables, while $\sigma_{\rank(X)}$ and $\sigma_{\rank(Y)}$ are the standard deviations of the ranks of $X$ and $Y$, respectively.
\end{definition}

Chatterjee's correlation coefficient, denoted by $\xi$, is designed to measure the degree of dependence between two variables without assuming any specific type of relationship. Given a dataset $(X, Y)$ with $n$ pairs, the coefficient is defined as:
\begin{equation}
\xi_n(X,Y) = 1 - \frac{3 \sum_{i=1}^{n-1} |r_{i+1} - r_i|}{n^2 - 1}
\end{equation}
where $r_i$ is the rank of $Y_i$ in the ordered sequence of $Y$ values corresponding to the sorted $X$ values. This coefficient ranges from 0 to 1, where 0 indicates independence and 1 indicates a perfect functional relationship. For the general case with ties, a more complex formula involving additional terms to handle the ties is used.

L2 regularization, also known as weight decay, is a common technique used to prevent overfitting in machine learning models, including Multi-Layer Perceptrons (MLPs). In the context of an MLP, L2 regularization adds a penalty term to the loss function that is proportional to the sum of the squares of the model parameters (weights). This encourages the model to keep the weights small, which can help improve generalization.

Let $\mathbf{W}^{(l)}$ represent the weight matrix for the $l$-th layer of the MLP, and let $\mathbf{b}^{(l)}$ denote the corresponding bias vector. The primary loss function of the network, $L_0$, could be any suitable loss function such as the mean squared error for regression or the cross-entropy loss for classification.

The L2 regularization term for a single layer is given by:
\begin{equation}
R(\mathbf{W}^{(l)}) = \frac{1}{2} \sum_{i=1}^{d_l} \sum_{j=1}^{h_l} \left( W^{(l)}_{ij} \right)^2,
\end{equation}
where $d_l$ and $h_l$ are the dimensions of the weight matrix $\mathbf{W}^{(l)}$, and $W^{(l)}_{ij}$ is the weight connecting the $i$-th input neuron to the $j$-th neuron in the $l$-th layer.

The total regularization term for the entire network, considering all layers, is:
\begin{equation}
R(\mathbf{W}) = \frac{1}{2} \sum_{l=1}^{L} \sum_{i=1}^{d_l} \sum_{j=1}^{h_l} \left( W^{(l)}_{ij} \right)^2,
\end{equation}
where $L$ is the total number of layers in the network.

The total loss function $L$ for the MLP, incorporating the L2 regularization term, is defined as:
\begin{equation}
L = L_0 + \lambda \; R(\mathbf{W}),
\end{equation}
where $\lambda$ is a scalar hyperparameter that controls the overall strength of the regularization.

By adding this regularization term, the optimization process aims to minimize the primary loss $L_0$ along with keeping the weights small, thereby helping to reduce the model complexity and prevent overfitting. The gradient descent updates for the weights will be adjusted to account for the regularization term, effectively shrinking the weights during the training process.


\section{Proposal}

The Chatterjee Redlining Penalty is a regularization term that penalizes the weights of features highly correlated with the sensitive attribute, as measured by Chatterjee's Xi Rank Correlation Coefficient. By incorporating this penalty into the loss function of the neural network, the model is encouraged to reduce its reliance on sensitive attributes, thus promoting fairer predictions.

Let $X \in \mathbb{R}^{n \times d}$ be a dataset where $n$ represents the number of instances and $d$ represents the number of features. Let $X_i \in \mathbb{R}^n$ denote the $i$-th feature of the dataset, and let $A = X_i \in \mathbb{R}^n$ be a sensitive (protected) feature for some $i$. In this neural network, $\mathbf{W}^{(1)} \in \mathbb{R}^{d \times h}$ is the weight matrix for the first hidden layer, with $h$ being the number of neurons in this layer. Additionally, $\lambda$ is a scalar that controls the overall strength of the regularization.

Thus, the proposed regularization term $R(\mathbf{W}^{(1)})$ applied to the weight matrix $\mathbf{W}^{(1)}$ of the first hidden layer is defined in Equation~\ref{eq:xi_reg}, where, the Chatterjee's Xi Correlation Coefficient $\xi_n(X_i,\,A)$ between the $i$-th input feature $X_i$ and the sensitive feature $A$ acts as the regularization strength for the $i$-th input feature. Here $W^{(1)}_{ij}$ are the weights connecting the $i$-th input feature to the $j$-th neuron in the first hidden layer. The greater $i$-th input feature dependence on sensitive feature the greater the penalization factor enforcing lower values to those weights

\begin{equation}\label{eq:xi_reg}
R(\mathbf{W}^{(1)}) = \sum_{i=1}^d \xi_n(X_i,\,A) \sum_{j=1}^h (W^{(1)}_{ij})^2,
\end{equation}


The total loss function $L$ for the multilayer perceptron (MLP), incorporating the sensitive-feature-specific $L_2$ regularization, is given by Equation~\ref{eq:total_regularized_loss}:
\begin{equation}\label{eq:total_regularized_loss}
L = L_0 + \lambda \; R(\mathbf{W}^{(1)}),
\end{equation}
where $L_0$ is the primary loss function of the network. This formulation ensures that the model's learning process penalizes the weights associated with features highly correlated with the sensitive attribute, thereby reducing the potential for biased decisions.


\section{Experimental setup}

\section{Results and discussion}
